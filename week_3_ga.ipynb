{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.datasets import _california_housing\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _california_housing.fetch_california_housing(as_frame=True).frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data, columns=_california_housing.fetch_california_housing()['feature_names'] + ['MedHouseVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc         0\n",
       "HouseAge       0\n",
       "AveRooms       0\n",
       "AveBedrms      0\n",
       "Population     0\n",
       "AveOccup       0\n",
       "Latitude       0\n",
       "Longitude      0\n",
       "MedHouseVal    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns='MedHouseVal')\n",
    "y=data['MedHouseVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.129631\n",
       "1        1.314156\n",
       "2        1.258693\n",
       "3        1.165100\n",
       "4        1.172900\n",
       "           ...   \n",
       "20635   -1.115804\n",
       "20636   -1.124470\n",
       "20637   -0.992746\n",
       "20638   -1.058608\n",
       "20639   -1.017878\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,y, test_size=0.4, shuffle=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression().fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse\n",
    "np.sqrt(np.mean((LinearRegression().fit(X_train,y_train).predict(X_test)-y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=LinearRegression().fit(X_train,y_train).predict(X_test)\n",
    "# variance score\n",
    "print(r2(y_test,y_pred))\n",
    "# max error\n",
    "print(np.max(np.abs(y_test-y_pred)))\n",
    "# mean absolute error\n",
    "print(np.mean(np.abs(y_test-y_pred)))\n",
    "# mean squared error\n",
    "print(np.mean((y_test-y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd=SGDRegressor(random_state=1)\n",
    "sgd.fit(X_train,y_train)\n",
    "y_pred=sgd.predict(X_test)\n",
    "# bias term \n",
    "print(sgd.intercept_)\n",
    "# weights\n",
    "print(sgd.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning the hyperparameters\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd=SGDRegressor(random_state=1)\n",
    "parameters = {'alpha':[0.1, 0.01, 0.001], 'max_iter':[1000,2000,5000],'penalty':['l1','l2']}\n",
    "clf = GridSearchCV(sgd, parameters,cv=4)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params=clf.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_best = SGDRegressor(alpha=best_params['alpha'], max_iter=best_params['max_iter'], penalty=best_params['penalty'])\n",
    "sgd_best.fit(X_train, y_train)\n",
    "# acuuracy\n",
    "print(sgd_best.score(X_test,y_test))\n",
    "# y_pred=sgd_best.predict(X_test)\n",
    "# bias term\n",
    "# print(sgd_best.intercept_)\n",
    "# weights\n",
    "# print(sgd_best.coef_)\n",
    "# score\n",
    "# print(sgd_best.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "parameters = {'alpha':[0.5,0.1,0.05,0.01,0.005,0.001],'max_iter':[1000,10000,100000]} \n",
    "ridge = Ridge()\n",
    "clf = GridSearchCV(ridge, parameters,cv=4)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params=clf.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring the model based on the best parameters\n",
    "ridge_best = Ridge(alpha=best_params['alpha'], max_iter=best_params['max_iter'])\n",
    "ridge_best.fit(X_train, y_train)\n",
    "# accuracy\n",
    "print(ridge_best.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfroming split again\n",
    "x_train,x_test,y_train,y_test= train_test_split(X,y, test_size=0.4, shuffle=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.05, 'max_iter': 1000}\n",
      "0.4521947009273938\n"
     ]
    }
   ],
   "source": [
    "# tunning the hyperparameters for lasso regression  \n",
    "# from sklearn.linear_model import Lasso\n",
    "parameters = {'alpha':[0.5,0.1,0.05,0.01,0.005,0.001],'max_iter':[1000,10000,100000]}\n",
    "lasso = Lasso() \n",
    "clf1 = GridSearchCV(lasso, parameters,cv=6)\n",
    "clf1.fit(x_train, y_train)   \n",
    "best_params1=clf1.best_params_    \n",
    "print(best_params1)\n",
    "\n",
    "# scoring the model based on the best parameters\n",
    "lasso_best = Lasso(alpha=best_params1['alpha'], max_iter=best_params1['max_iter'],fit_intercept=True)\n",
    "lasso_best.fit(x_train, y_train)\n",
    "# accuracy\n",
    "print(lasso_best.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe=OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\vvagh\\OneDrive - Indian Institute of Science Education and Research Bhopal\\Documents\\IITM Stuff\\diploma-LittleBeasty\\dataset.csv\")\n",
    "# df.describe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Encode target\n",
    "y = oe.fit_transform(df[['Target']]).ravel()\n",
    "\n",
    "# Drop the target column from X\n",
    "X = df.drop('Target', axis=1)\n",
    "\n",
    "# Define the columns for preprocessing\n",
    "impute_cols = [0, 1]\n",
    "scaler_cols = [0, 1, 2, 3]\n",
    "onehot_cols = [4]\n",
    "\n",
    "# Define the preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mean_imputer', SimpleImputer(strategy='mean'), impute_cols),\n",
    "        ('scaler', StandardScaler(), scaler_cols),\n",
    "        ('ordinalEncoder', OrdinalEncoder(), onehot_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the pipeline with preprocessing, RFE, and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('sfs', SequentialFeatureSelector(LogisticRegression(), n_features_to_select=2, direction='backward')),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the transformed features\n",
    "preprocessed_X = pipeline.named_steps['preprocessor'].transform(X)\n",
    "print(\"Shape of transformed X:\", preprocessed_X.shape)\n",
    "\n",
    "# Get selected features after RFE\n",
    "selected_feature_indices = pipeline.named_steps['sfs'].get_support(indices=True)\n",
    "\n",
    "# Print the selected features\n",
    "print(f\"Selected features: {selected_feature_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[selected_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
