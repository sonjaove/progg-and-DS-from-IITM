{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uBUor5KWp3_Q",
        "FSDbBz7ucm_a",
        "5eh8cI4PeVEb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonjaove/progg-and-DS-from-IITM/blob/ML/W5_Programming_withoutSol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "WT2nf7VJXHsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kgvCN0n3_1p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignments has two sections:\n",
        "* Linear Regression\n",
        "* Kernel Regression\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBY90BqPXO31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1:\n",
        "\n",
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "X1nmn2q15Vzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Boston_housing dataset for the regression problem. Run the below cell to get the following variables:\n",
        "* `Training_data` = Training data matrix of shape $(n, d)$\n",
        "* `labels` = label vector corresponding to the training data\n",
        "* `test_data` = Test data matrix of shape $(n_1, d)$ where $n_1$ is the number of examples in test dataset.\n",
        "* `test_labels` = label vector corresponding to the test data\n",
        "\n",
        "Use this dataset for the regression problem."
      ],
      "metadata": {
        "id": "aComJ_Fd5dnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing\n",
        "Train, test = boston_housing.load_data(seed= 111)\n",
        "Training_data, labels = Train[0], Train[1]\n",
        "Test_data, test_labels = test[0], test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UCtcH64nsC",
        "outputId": "80999439-c3d1-48bb-e213-138c23ee41bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "R0Dnj-Qha47p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "vpLeerN2mGRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "How many examples are there in the test dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ChYFPOV5b5jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "0XK7s98bb8PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "How many features are there in the dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYLLXlAacL5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "rGvr9_jkO7NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression model for the dataset ${\\mathbb{x}, y}$ is given as\n",
        "$$h_w(\\mathbb{x}) = w_1x^{1}+w_2x^{2}+...+w_dx^{d} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "where $x^{i}$ is the $i^{th}$ feature, $\\mathbb{x}$ is the feature matrix of shape $(d, n)$ and $w = [w_1, w_2, ...w_d]^T$ is the weight vector.\n",
        "\n",
        "\n",
        "Notice that above model always pass through the origin but for a given dataset, best fit model need not pass through the origin. To tackle this issue, we add an intercept $w_0$ in the model and set the corresponding featrue $x^{0}$ to $1$. That is\n",
        "\n",
        "$$h_w(\\mathbb{x}) =w_0x^{0}+ w_1x^{1}+w_2x^{2}+...+w_dx^{n} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "We call $x^{0}$ the dummy feature and set its value to 1 for each examples. Now $w$ is of shape $(d+1, 1)$ and $\\mathbb{x}$ is of shape $(d+1, n)$ where the first row of $\\mathbb{x}$ has entries as 1.\n"
      ],
      "metadata": {
        "id": "KmF4HhMmhx9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "Add the dummy feature in the feature matrix `Training_data` and test data matrix `test_data`. We will be using this new feature matrices (after adding te dummy feature) for learning the model.\n",
        "\n",
        "Note: As per your convenience, you can convert the shape of the training dataset to $(d, n)$."
      ],
      "metadata": {
        "id": "kN5fsfqfmX_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "wic4nhW47fOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "If the solution of optimization problem is obtained by setting the first derivative of loss function (squared loss) to zero, find the value of $w_0+w_1+...w_d$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sK4oWgqCnzgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "JORYNRkdOo55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "Find the average of the predictions made by the above model.\n",
        "\n"
      ],
      "metadata": {
        "id": "uBUor5KWp3_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "O2vF1aE2Rxfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Find the loss for the training data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "FSDbBz7ucm_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "F4jRui2VSeDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "\n",
        "Find the loss for the test data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "5eh8cI4PeVEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "vBMCgEIBU6v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "Find the weights using the gradient descent. Use a constant learning rate of $\\eta = 10^{-10}$. Initialize the weight vector as zero vector and update the weights for 100 iterations. Enter the sum of all the weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "NkeClcplfJLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "QbpyGnfgWEqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "78ApH0oAg96X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "oI1yIf9N8la7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "FA7UKT1Y3PXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "tevVzIIj3SZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 11\n",
        "Find the weights using the stochastic gradient descent. Use a constant learning rate of $\\eta = 10^{-8}$. Initialize the weight vector as zero vector and update the weights for 1000 iterations. . Take the batch size of $⌈\\text{number of samples}/5⌉ $. For sampling the batch examples in $ith$ iteration, set seed at $i$. The final weight is the last updated weight. Do not take the avearge of weights updated in all the iterations. Enter the sum of all the weights.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AoLsBKc31Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "R4odop9yF9VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 12\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "yPzJLciH4NrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "w9usLAPeLNkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 13\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n"
      ],
      "metadata": {
        "id": "rfeamQM94x_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "oF1xpNH845iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2:\n",
        "\n",
        "**kernel Regression**"
      ],
      "metadata": {
        "id": "muMOKLvY5D9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will generate the synthetic dataset for the kernel regression problem. Run the following cell to get the following variables:\n",
        "\n",
        "`X` = Training data matrix of shape $(n, d)$. In the given dataset $d = 1$.\n",
        "\n",
        "`y` = label vector corresponding to the training dataset"
      ],
      "metadata": {
        "id": "pDAKRJua6rCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 101)\n",
        "X = np.arange(-2, 2, 0.01).reshape(-1, 1)\n",
        "y = X**3 + rng.normal(0, 1, X.shape[0]).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "_WgICXZSnra0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 14\n",
        "\n",
        "Plot the scatter plot between feature and the labels. Enter your answer as 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "y_-9lyPm8aaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "B12Nc2Sv80_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 15\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "E3e-gQHg8z8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "xGeqMCV57ZJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "\n",
        "Add the dummy feature in the feature matrix `X`and reshape it to the shape $(d, n)$."
      ],
      "metadata": {
        "id": "uPifeX-K9zuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "yduBBJQgujfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 16\n",
        "\n",
        "Our task is to apply the kernel regression with polynomial kernel of degree 3. We know that weight vector can be written as\n",
        "\n",
        "$$w = \\phi(\\mathbb{x})\\alpha$$\n",
        "\n",
        "let us call the vector $\\alpha$ as coefficient vector. Find the sum of elements in the coefficient vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "HQtBOQua_HQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "CVMDkgkNqCBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 17\n",
        "\n",
        "Find the sum of the predictions made by the kernel regression model of degree 3.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xq0YtsGjA7IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "YAqln4GZ05dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 18\n",
        "\n",
        "Find the loss for the training data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "pXRpijIeCcSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "8_i2Th-g1ToW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test dataset\n",
        "\n",
        "run the following cell to get the test data matrix `X_test` and corresponding label vector `y_test`."
      ],
      "metadata": {
        "id": "nGpw3zpI65rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 102)\n",
        "Xnew = np.arange(-2, 2, 0.03)\n",
        "ynew = Xnew**3 + rng.normal(0, 1.5, Xnew.shape[0])\n",
        "X_test = np.column_stack((np.ones(Xnew.shape[0]), Xnew.reshape(-1, 1))).T\n",
        "y_test = ynew.reshape(-1, 1)\n",
        "plt.scatter(Xnew,ynew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fLNDYH_B67kN",
        "outputId": "23f47e9c-4498-4cbc-d1de-816210d576bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f5ced9eb150>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 19\n",
        "\n",
        "Find the loss for the test data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "5vlunIBzDI1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "_RxSPslY7joK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}